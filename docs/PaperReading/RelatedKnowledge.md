# 相关知识学习

## 监督学习和无监督学习
监督学习的目标往往是让计算机去学习我们已经创建好的分类系统（模型）
监督学习是训练神经网络和决策树的常见技术。
常见的有监督学习算法：回归分析和统计分类。最典型的算法是KNN和SVM。（用来做分类）

无监督学习：输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，类间差距最大化。通俗点将就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。（聚类）

1.      有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。

2.      有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。

3.      非监督学习方法在寻找数据集中的规律性，这种规律性并不一定要达到划分数据集的目的，也就是说不一定要"分类"。

## GAN

生成式对抗网络

属于无监督学习
有生成模型和判别模型两个模型
生成模型：给一系列猫咪，生成一张新的猫咪
判别模型：判断一张图片里的动物是什么类别

生成网络的目的是尽量生成真实的图片去欺骗判别网络，使判别网络无法分辨出生成网络生成的图片是真实的还是生成的。

判别网络的目的是判断生成网络生成的图片是真实的还是生成的。

传统的机器学习方法一般会先定义一个模型，再让数据去学习，而GAN的生成模型最后可以通过噪声生成一个完整的真实数据，说明生成模型掌握了从随机噪声到人脸数据的分布规律


## VAE

变分自编码器

属于无监督学习
有编码器和解码器两部分

推断网络通过对原始数据的变分推断生成隐变量的变分概率分布，再由生成网络生成样本。

### 数学原理

VAE的目标是学习复杂数据的概率分布，通过最大化数据的对数似然：

$$p(x) = \int p(x|z)p(z)dz$$

直接计算上述积分通常是不可行的，VAE通过引入近似后验分布$q_\phi(z|x)$来近似真实后验分布$p(z|x)$。

VAE的损失函数是证据下界(ELBO)：

$$\log p(x) \geq \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$$

其中第一项是重构误差，第二项是正则化项，使编码分布接近先验分布。

### 概率论与数理统计

#### 1. 贝叶斯定理

贝叶斯定理的标准形式：

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

扩展形式（全概率公式展开）：

$$
P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^n P(B|A_j)P(A_j)}
$$

#### 2. 条件概率

条件概率表示在给定事件B发生的条件下，事件A发生的概率：

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

条件概率的链式法则：

$$P(A_1, A_2, ..., A_n) = P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_1, A_2) \cdot ... \cdot P(A_n|A_1, A_2, ..., A_{n-1})$$

对于满足马尔科夫性质的随机过程，上述链式法则可以简化：

$$P(A_1, A_2, ..., A_n) = P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_2) \cdot ... \cdot P(A_n|A_{n-1})$$

#### 3. 马尔科夫链

马尔科夫链是一个随机过程，具有无记忆性：

$$
P(X_{t+1} = x|X_t = x_t, X_{t-1} = x_{t-1}, ..., X_0 = x_0) = P(X_{t+1} = x|X_t = x_t)
$$

转移概率矩阵：

$$
P = \begin{bmatrix}
p_{11} & p_{12} & \cdots & p_{1n} \\
p_{21} & p_{22} & \cdots & p_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
p_{n1} & p_{n2} & \cdots & p_{nn}
\end{bmatrix}
$$

[马尔科夫链](https://zhuanlan.zhihu.com/p/448575579)

#### 4. KL散度（相对熵）

KL散度用于衡量两个概率分布的差异：

$$
D_{KL}(P||Q) = \sum_{x \in \mathcal{X}} P(x) \log \frac{P(x)}{Q(x)}
$$

连续形式：

$$
D_{KL}(P||Q) = \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} dx
$$

##### 高斯分布的KL散度公式

对于两个多元高斯分布$P = \mathcal{N}(\mu_1, \Sigma_1)$和$Q = \mathcal{N}(\mu_2, \Sigma_2)$，它们之间的KL散度为：

$$D_{KL}(P||Q) = \frac{1}{2}\left[\log\frac{|\Sigma_2|}{|\Sigma_1|} - d + \text{tr}(\Sigma_2^{-1}\Sigma_1) + (\mu_2 - \mu_1)^T\Sigma_2^{-1}(\mu_2 - \mu_1)\right]$$

其中$d$是维度，$|\Sigma|$表示协方差矩阵的行列式，$\text{tr}$表示矩阵的迹。

对于一元高斯分布$P = \mathcal{N}(\mu_1, \sigma_1^2)$和$Q = \mathcal{N}(\mu_2, \sigma_2^2)$，KL散度简化为：

$$D_{KL}(P||Q) = \log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}$$

[信息熵、交叉熵、相对熵（KL散度）](https://zhuanlan.zhihu.com/p/573385147)

#### 5. 极大似然估计（MLE）

给定观测数据$X$，寻找参数$\theta$使得似然函数最大：

$$
\hat{\theta}_{MLE} = \arg\max_{\theta} P(X|\theta)
$$

对数似然函数：

$$
\mathcal{L}(\theta) = \log P(X|\theta) = \sum_{i=1}^n \log P(x_i|\theta)
$$

[极大似然估计](https://www.zhihu.com/question/24124998/answer/1547063354)

### 信息论基础

#### 1. 熵（Entropy）

离散随机变量的熵：

$$
H(X) = -\sum_{x \in \mathcal{X}} p(x) \log p(x)
$$

连续随机变量的微分熵：

$$
h(X) = -\int_{\mathcal{X}} p(x) \log p(x) dx
$$

#### 2. 互信息（Mutual Information）

互信息衡量两个随机变量的依赖程度：

$$
I(X;Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
$$

连续形式：

$$
I(X;Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)p(y)} dxdy
$$

[互信息](https://www.zhihu.com/question/304499706/answer/31256368530)

#### 3. 交叉熵（Cross Entropy）

交叉熵用于衡量两个概率分布之间的差异：

$$
H(P,Q) = -\sum_{x \in \mathcal{X}} P(x) \log Q(x)
$$

连续形式：

$$
H(P,Q) = -\int_{\mathcal{X}} p(x) \log q(x) dx
$$

### 随机过程

#### 1. 马尔可夫过程

马尔可夫过程是一个随机过程，其未来状态只依赖于当前状态：

$$
P(X_{t+1} = x|X_t = x_t, X_{t-1} = x_{t-1}, ..., X_0 = x_0) = P(X_{t+1} = x|X_t = x_t)
$$

[马尔可夫过程](https://zhuanlan.zhihu.com/p/86995916)

#### 2. 扩散过程

扩散过程可以用随机微分方程描述：

$$
dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t
$$

其中：

- $\mu(X_t, t)$是漂移项
- $\sigma(X_t, t)$是扩散项
- $W_t$是维纳过程（布朗运动）

### 参数重整化（重参数化）技巧

参数重整化是VAE中解决梯度反向传播问题的关键技术。由于从分布中采样的操作不可导，无法通过反向传播计算梯度，因此使用重参数化技巧。

对于正态分布，重参数化过程如下：

1. 从标准正态分布中采样：$\epsilon \sim \mathcal{N}(0, I)$
2. 将样本转换为所需分布：$z = \mu + \sigma \odot \epsilon$

这样，随机性从网络中分离出来，使得梯度可以通过确定性函数反向传播。

## VAE详解

### 单层VAE
单层VAE由编码器和解码器组成：

1. 编码器：将输入数据$x$映射到隐变量分布的参数$\mu$和$\sigma$
2. 解码器：将隐变量$z$映射回原始数据空间

训练目标是最大化证据下界(ELBO)：

$$\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$$

其中：
- 第一项是重构误差，确保解码的数据与原始数据相似
- 第二项是正则化项，确保隐变量分布接近标准正态分布

### 多层VAE

多层VAE通过堆叠多个编码器和解码器层，或使用更复杂的网络结构，来提高模型表达能力。常见的包括：

1. 层次VAE：使用多层隐变量，每层捕获不同抽象级别的特征
2. 条件VAE：在隐变量分布中加入条件信息
3. VQ-VAE：使用向量量化技术离散化隐空间

## Diffusion Model

扩散模型是一类基于逐步添加和移除噪声的生成模型，其主要思想是：

1. 前向过程：逐步向数据添加高斯噪声，直到完全破坏原始数据结构，变为纯噪声
2. 反向过程：学习如何逐步去除噪声，恢复原始数据

### 数学原理

扩散模型的前向过程是一个固定的马尔可夫链：

$$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_tI)$$

经过推导，可以直接计算任意时间步的分布：

$$q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)I)$$

其中$\alpha_t = 1-\beta_t$，$\bar{\alpha}_t = \prod_{s=1}^{t}\alpha_s$。

反向过程学习条件概率$p_\theta(x_{t-1}|x_t)$，通常参数化为高斯分布：

$$p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

训练目标是最小化变分下界，可以简化为预测添加的噪声：

$$L_{simple}(\theta) = \mathbb{E}_{t,x_0,\epsilon}[||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t)||^2]$$

### 与VAE的关系

扩散模型可以看作是VAE的特例，但有显著区别：

1. VAE使用单步编码-解码，而扩散模型使用多步噪声添加和去除
2. VAE的隐空间通常是低维的，而扩散模型的中间状态与原始数据维度相同
3. 扩散模型的前向过程是固定的，不需要学习

两者都使用变分推断优化证据下界(ELBO)，但在具体实现和优化方式上有明显差异。


